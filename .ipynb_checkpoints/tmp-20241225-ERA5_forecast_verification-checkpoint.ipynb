{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca503c55-fb66-4ecd-934d-85f174d9de7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ERA5 forecast diagnostics\n",
    "# initial built: 2024/12/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30382f5f-a374-40c3-9f35-85811419bd2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os, shutil, sys\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import netCDF4 as nc\n",
    "\n",
    "sys.path.append('/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/GribDiag/lib')\n",
    "import read_grib as rglib\n",
    "import plot_grib as plib\n",
    "import general_lib as glib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45e5e1-287a-4a92-b8f3-6bdf805f0965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c28c8-76bf-4049-975c-9e086e52082e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984cf65c-d080-474f-905f-8df08b000249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getmask(readmask=False):\n",
    "    \"\"\" create mask DataArray \"\"\"\n",
    "\n",
    "    print (f'analdir = {analdir}')\n",
    "    masknc = f'{savedir}/mask.nc'\n",
    "    print (f'masknc = {masknc}')\n",
    "    \n",
    "    if readmask and os.path.exists(masknc):\n",
    "        mask = xr.load_dataset(masknc)['mask']\n",
    "        pfull = mask.level.values\n",
    "\n",
    "    else:\n",
    "        \"\"\" get surface pressure from experiment forecast \"\"\"\n",
    "        fcstdate = sdate-datetime.timedelta(hours=6)\n",
    "        fcstcyc  = fcstdate.strftime(\"%Y%m%d%H\")\n",
    "        fhr=fhrs[0]\n",
    "        ne=0\n",
    "        for e, eid in enumerate(expids):\n",
    "            fcstfn = os.path.join(f'{fcsthome}/{expdic[eid]}',f'pgbf{fhr}.gfs.{fcstcyc}.grib2')\n",
    "            plgrib = os.path.join(f'{workdir}', 'fcst.grib')\n",
    "            fcstnc = os.path.join(f'{workdir}', 'fcst.nc')\n",
    "            spgrib = os.path.join(f'{workdir}', 'fcstsp.grib')\n",
    "            \"\"\" assuming all forecast files have the same dimension \"\"\"\n",
    "            if e == 0:\n",
    "                if os.path.exists(plgrib):\n",
    "                    os.remove(plgrib)\n",
    "                subprocess.run([\"grib_copy\", \"-w\", \"levtype=pl,shortName=t\", fcstfn, plgrib])\n",
    "                subprocess.run([\"grib_to_netcdf\", \"-D\" \"NC_FLOAT\", \"-o\", fcstnc, plgrib])\n",
    "                fcst   = xr.load_dataset(fcstnc)\n",
    "                ftime  = fcst.time.values[0]\n",
    "                pfullf = fcst.level.values\n",
    "                latf   = fcst.latitude.values\n",
    "                lonf   = fcst.longitude.values\n",
    "            if os.path.exists(spgrib):\n",
    "                os.remove(spgrib)\n",
    "            subprocess.run([\"grib_copy\", \"-w\", \"shortName=sp\", fcstfn, spgrib]) # sp = sea pressure\n",
    "            fcstsp = xr.load_dataset(spgrib, engine=\"cfgrib\")\n",
    "            if e == 0:\n",
    "                psfc = fcstsp.sp.values\n",
    "            else:\n",
    "                psfc = psfc + fcstsp.sp.values\n",
    "            ne += 1\n",
    "\n",
    "        \"\"\" get surface pressure from analysis \"\"\"\n",
    "        analcyc = sdate.strftime(\"%Y%m%d%H\")\n",
    "        ayyyy   = analcyc[:4]\n",
    "        amm     = analcyc[4:6]\n",
    "        \n",
    "        analnc = os.path.join(analdir, f'{aprefix}.{era5fndic[varids[0]]}.{ayyyy}.{amm}.nc')\n",
    "        spnc   = os.path.join(analdir, f'sfc.ps.{ayyyy}.{amm}.nc')\n",
    "\n",
    "        \"\"\" get analysis pressure levels \"\"\"\n",
    "        if not os.path.exists(analnc):\n",
    "            raise SystemExit(f'{analnc} not exist')\n",
    "        anal   = xr.load_dataset(analnc).sel(valid_time=ftime)\n",
    "        pfulla = anal.pressure_level.values\n",
    "        \n",
    "        \"\"\" analysis surface pressure \"\"\"\n",
    "        if not os.path.exists(spnc):\n",
    "            raise SystemExit(f'{spnc} not exist')\n",
    "        analsp = xr.load_dataset(spnc).sel(valid_time=ftime)\n",
    "        \n",
    "        \"\"\" regrid ERA5 dataset to forecast dataset resolution \"\"\"\n",
    "        lata = analsp.latitude.values\n",
    "        lona = analsp.longitude.values\n",
    "\n",
    "        if not np.array_equiv(lata,latf) or not np.array_equiv(lona,lonf):\n",
    "            ds_out = xr.Dataset(\n",
    "                {\n",
    "                   \"lat\": ([\"lat\"], latf),\n",
    "                   \"lon\": ([\"lon\"], lonf),\n",
    "                }\n",
    "            )\n",
    "            regridder = xe.Regridder(analsp, ds_out, \"bilinear\")\n",
    "            analsp = regridder(analsp)\n",
    "\n",
    "        print (analsp.sp.values)\n",
    "        psfc = psfc + analsp.sp.values\n",
    "        ne += 1\n",
    "        ne_inv=0.01/ne\n",
    "        psfc = psfc * ne_inv\n",
    "\n",
    "        psfcarray=xr.DataArray(\n",
    "        data=psfc,\n",
    "        coords={\n",
    "            \"latitude\": latf,\n",
    "            \"longitude\": lonf,\n",
    "        },\n",
    "        dims=[\"latitude\", \"longitude\"],\n",
    "        name='psfc'\n",
    "        )\n",
    "\n",
    "        psfcarray.to_netcdf(f'{savedir}/psfc.nc')\n",
    "        \n",
    "        \"\"\" create mask DataArray \"\"\"\n",
    "        maskdata = np.ones(fcst.t.values.shape, dtype=bool)\n",
    "        pfull    = np.intersect1d(pfulla,pfullf)\n",
    "        print ('pfulla ', pfulla)\n",
    "        print ('pfullf ', pfullf)\n",
    "        print ('pfull ', pfull)\n",
    "        maskdata = np.ones((len(pfull), psfc.shape[0], psfc.shape[1]))\n",
    "        for l, pres in enumerate(pfull.tolist()):\n",
    "            cutoff=800\n",
    "            if pres < cutoff:\n",
    "                cutoff = pres\n",
    "            maskdata[l,:,:] = (psfc > cutoff)\n",
    "\n",
    "        mask=xr.DataArray(\n",
    "        data=maskdata,\n",
    "        coords={\n",
    "            \"level\": pfull,\n",
    "            \"latitude\": latf,\n",
    "            \"longitude\": lonf,\n",
    "        },\n",
    "        dims=[\"level\", \"latitude\", \"longitude\"],\n",
    "        name='mask'\n",
    "        )\n",
    "\n",
    "        mask.to_netcdf(masknc)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e057e7d5-bdd3-4e5d-9c57-66ecdbffe499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_anal(cdate,vtime,pfull,latf,lonf,anal0=None):\n",
    "    \"\"\" read analysis and forecast data \"\"\"\n",
    "\n",
    "    readdata=True\n",
    "    analcyc=cdate.strftime(\"%Y%m%d%H\")\n",
    "    print (f'analysis cycle {analcyc}')\n",
    "\n",
    "    ayyyy=analcyc[:4]\n",
    "    amm=analcyc[4:6]\n",
    "    if anal0 is not None and vtime in anal0.time.values:\n",
    "        print ('ERA5: skip reading analysis data')\n",
    "        anal = anal0\n",
    "        readdata=False\n",
    "    else:\n",
    "        for v, varid in enumerate(varids):\n",
    "            if varid == 'vw' and not 'u' in varids and not 'v' in varids:\n",
    "                analu = os.path.join(analdir, f'lev.ua.{ayyyy}.{amm}')\n",
    "                analv = os.path.join(analdir, f'lev.va.{ayyyy}.{amm}')\n",
    "                tmp = xr.load_dataset(analu).sel(level=pfull)\n",
    "                if v == 0:\n",
    "                    anal = tmp\n",
    "                else:\n",
    "                    anal = xr.merge([anal, tmp])\n",
    "                tmp = xr.load_dataset(analv).sel(level=pfull)\n",
    "                anal.merge(anal,tmp)\n",
    "            else:\n",
    "                analfn = os.path.join(analdir, f'{aprefix}.{era5fndic[varid]}.{ayyyy}.{amm}.nc')\n",
    "                print (analfn)\n",
    "                if levtype == 'isobaricInhPa' or levtype == 'heightAboveGround':\n",
    "                    tmp = xr.load_dataset(analfn).sel(level=pfull)\n",
    "                else:\n",
    "                    \"\"\" single level data \"\"\"\n",
    "                    tmp = xr.load_dataset(analfn)\n",
    "                    if varid == 'lcc':\n",
    "                        tmp = tmp * 100.\n",
    "                if v == 0:\n",
    "                    anal = tmp\n",
    "                else:\n",
    "                    anal = xr.merge([anal, tmp])\n",
    "\n",
    "        \"\"\" regrid dataset \"\"\"\n",
    "        lata=anal.latitude.values\n",
    "        lona=anal.longitude.values\n",
    "        if not np.array_equiv(lata,latf) or not np.array_equiv(lona,lonf):\n",
    "            print ('regrid data')\n",
    "            ds_out = xr.Dataset(\n",
    "                {\n",
    "                   \"latitude\": ([\"latitude\"], latf),\n",
    "                   \"longitude\": ([\"longitude\"], lonf),\n",
    "                }\n",
    "            )\n",
    "            regridder = xe.Regridder(anal, ds_out, \"bilinear\")\n",
    "            anal = regridder(anal)\n",
    "\n",
    "        \"\"\" rename variables \"\"\"\n",
    "        newname = {}\n",
    "        for var in varids:\n",
    "            if var in era5vardic.keys():\n",
    "                key = era5vardic[var]\n",
    "                newname[key] = var\n",
    "        anal = anal.rename(name_dict=newname)\n",
    "\n",
    "    return anal, readdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d31dcf86-465c-4971-b386-94b098aa1058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_fcst(cdate,fhr,pfull):\n",
    "    gdate = cdate - datetime.timedelta(hours=6)\n",
    "    fcstcyc = gdate.strftime(\"%Y%m%d%H\")\n",
    "    fcst={}\n",
    "    for e, eid in enumerate(expids):\n",
    "        fcstfn = os.path.join(f'{fcsthome}/{expdic[eid]}',f'pgbf{fhr}.gfs.{fcstcyc}.grib2')\n",
    "        print ('fcstfn: ', fcstfn)\n",
    "        plgrib=os.path.join(f'{workdir}', 'fcst.grib')\n",
    "        if os.path.exists(plgrib):\n",
    "            os.remove(plgrib)\n",
    "        if levtype == 'isobaricInhPa':\n",
    "            subprocess.run([\"grib_copy\", \"-w\", f\"typeOfLevel={levtype}\", fcstfn, plgrib])\n",
    "\n",
    "            # CCH: 2024/09/25:\n",
    "            fcstnc=os.path.join(f'{workdir}', f'fcst.{fcstcyc}.nc')\n",
    "            if os.path.exists(fcstnc):\n",
    "                os.remove(fcstnc)\n",
    "            subprocess.run([\"grib_to_netcdf\", \"-D\" \"NC_FLOAT\", \"-o\", fcstnc, plgrib])\n",
    "\n",
    "            fcst[eid] = xr.load_dataset(fcstnc).sel(level=pfull).isel(time=0)[varids]\n",
    "        else:\n",
    "            \"\"\" single level data \"\"\"\n",
    "            vlist = []\n",
    "            for varid in varids:\n",
    "                subprocess.run([\"grib_copy\", \"-w\", f\"shortName={varid},stepType={steptype}\", fcstfn, plgrib])\n",
    "                fcstnc=os.path.join(f'{workdir}', f'fcst.{fcstcyc}.nc')\n",
    "                if os.path.exists(fcstnc):\n",
    "                    os.remove(fcstnc)\n",
    "                subprocess.run([\"grib_to_netcdf\", \"-D\" \"NC_FLOAT\", \"-o\", fcstnc, plgrib])\n",
    "                ftmp = xr.load_dataset(fcstnc).isel(time=0)\n",
    "                vlist.append(ftmp)\n",
    "            if len(vlist) > 1:\n",
    "                fcst[eid] = xr.merge(vlist)\n",
    "            else:\n",
    "                fcst[eid] = ftmp\n",
    "\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c2cc53-0cab-49ca-9661-a601ba0ebec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xarray_t_test_interval(ds,ci_coords,ci_dims,axis=0,alpha=0.95):\n",
    "\n",
    "    \"\"\" get confidence interval for dataset:\n",
    "        ds: input dataset\n",
    "        ci_coords: input coordiates for output ci dataset\n",
    "        ci_dims: input dims for output ci dataset \"\"\"\n",
    "\n",
    "    v = 0\n",
    "    for var, da in ds.data_vars.items():\n",
    "        #print (var, da.values.shape)\n",
    "        hci = glib.t_test_interval(da.values,axis=axis,alpha=alpha)\n",
    "        #print (hci.shape)\n",
    "        tmp = xr.DataArray(hci, coords = ci_coords, dims = ci_dims, name=var)\n",
    "        if v == 0:\n",
    "            hci_xr = tmp\n",
    "        else:\n",
    "            hci_xr = xr.merge([hci_xr, tmp])\n",
    "        v += 1\n",
    "\n",
    "    return hci_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ffd156-9b81-480e-a8b9-b596fb97991c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_stats(fhr,mask,savedata=True):\n",
    "    \"\"\" read forecast and analysis, compute variable mean, rmse, bias \"\"\"\n",
    "\n",
    "    fmean={}; ermse={}; ebias={}; zmean_rmse={}; dzmean_rmse={}; d95={}\n",
    "    zmean_fma2={}; zmean_rmse={}; zmean_rmse_t={}\n",
    "    ntime = 0\n",
    "    cdate=sdate\n",
    "    while cdate <= edate:\n",
    "        \"\"\" 1. first read analysis and forecast data \"\"\"\n",
    "        fcst={}\n",
    "        if mask is not None:\n",
    "            pfull = mask.level.values\n",
    "        else:\n",
    "            pfull = None\n",
    "\n",
    "        fcst = read_fcst(cdate,fhr,pfull)\n",
    "        ftime = fcst[expids[0]].time.values\n",
    "        latf = fcst[expids[0]].latitude.values\n",
    "        lonf = fcst[expids[0]].longitude.values\n",
    "        if vrfy != 'ERA5':\n",
    "            anal = read_anal(cdate,ftime,pfull,latf,lonf)\n",
    "        else:\n",
    "            if cdate == sdate:\n",
    "                print ('read ERA5 data')\n",
    "                analrd, readdata = read_anal(cdate,ftime,pfull,latf,lonf)\n",
    "                anal0 = analrd\n",
    "            else:\n",
    "                analrd, readdata = read_anal(cdate,ftime,pfull,latf,lonf,anal0=anal0)\n",
    "                if readdata:\n",
    "                    print ('read ERA5 data')\n",
    "                    anal0 = analrd\n",
    "            print (analrd)\n",
    "            print ('ffff ', ftime)\n",
    "            if steptype == 'avg':\n",
    "                ptime = []\n",
    "                for dhr in np.arange(avghour)[::-1]:\n",
    "                    ptime.append(cdate-datetime.timedelta(hours=int(dhr)))\n",
    "                anal = analrd.sel(time=ptime).mean(dim='time')\n",
    "            else:\n",
    "                anal = analrd.sel(time=ftime)\n",
    "            print (anal)\n",
    "\n",
    "        if ntime == 0:\n",
    "            amean = anal\n",
    "        else:\n",
    "            amean += anal\n",
    "        if mask is not None:\n",
    "            amean = amean.where(mask)\n",
    "\n",
    "        for e, exp in enumerate(expids):\n",
    "\n",
    "            fma = fcst[exp] - anal\n",
    "\n",
    "            if 'vw' in varids:\n",
    "                vwfcst = np.sqrt(np.square(fcst[exp].u) + np.square(fcst[exp].v))\n",
    "                if anal is not None:\n",
    "                    vwanal = np.sqrt(np.square(anal.u) + np.square(anal.v))\n",
    "                else:\n",
    "                    if e == 0:\n",
    "                        vwanal = vwfcst\n",
    "                fma_vw = vwfcst - vwanal\n",
    "                fma = xr.merge([fma,fma_vw])\n",
    "            fma2 = fma*fma\n",
    "\n",
    "            \"\"\" sum datasets over time \"\"\"\n",
    "            if ntime == 0:\n",
    "                fmean[exp] = fcst[exp]\n",
    "                ebias[exp] = fma\n",
    "                ermse[exp] = fma2\n",
    "                if mask is not None:\n",
    "                    zmean_fma2[exp] = fma2.where(mask).mean(dim=\"longitude\")\n",
    "                else:\n",
    "                    zmean_fma2[exp] = fma2.mean(dim=\"longitude\")\n",
    "            else:\n",
    "                fmean[exp] += fcst[exp]\n",
    "                ebias[exp] += fma\n",
    "                ermse[exp] += fma2\n",
    "                if mask is not None:\n",
    "                    zmean_fma2[exp] = xr.concat([zmean_fma2[exp],fma2.where(mask).mean(dim=\"longitude\")], \"time\")\n",
    "                else:\n",
    "                    zmean_fma2[exp] = xr.concat([zmean_fma2[exp],fma2.mean(dim=\"longitude\")], \"time\")\n",
    "\n",
    "            if mask is not None:\n",
    "                #fmean[exp] = fcst[exp].where(mask)\n",
    "                fmean[exp] = fmean[exp].where(mask)\n",
    "                ebias[exp] = ebias[exp].where(mask)\n",
    "                ermse[exp] = ermse[exp].where(mask)\n",
    "\n",
    "        ntime += 1\n",
    "        cdate += delta\n",
    "    \"\"\" compute mean stats \"\"\"\n",
    "    \"\"\" https://www.tandfonline.com/doi/full/10.3402/tellusa.v68.30229 \"\"\"\n",
    "\n",
    "    rtime=1.0/ntime\n",
    "\n",
    "    \"\"\" mean analysis \"\"\"\n",
    "    amean = amean * rtime\n",
    "\n",
    "    \"\"\" mean forecast and forecast stats \"\"\"\n",
    "    for e, exp in enumerate(expids):\n",
    "        fmean[exp] = fmean[exp] * rtime\n",
    "        ebias[exp] = ebias[exp] * rtime\n",
    "        ermse[exp] = np.sqrt(ermse[exp] * rtime)\n",
    "        if \"time\" in zmean_fma2[exp].dims:\n",
    "            zmean_rmse[exp] = np.sqrt(zmean_fma2[exp].mean(dim=\"time\"))\n",
    "        else:\n",
    "            zmean_rmse[exp] = np.sqrt(zmean_fma2[exp])\n",
    "        \"\"\" zonal mean rmse over n forecast \"\"\"\n",
    "        zmean_rmse_t[exp] = np.sqrt(zmean_fma2[exp])\n",
    "    \"\"\" normalized zonal mean rmse difference \"\"\"\n",
    "    for e, exp in enumerate(expids[1:]):\n",
    "        \"\"\" assuming the first experiment is the CNTL \"\"\"\n",
    "        drmse = zmean_rmse_t[exp] - zmean_rmse_t[expids[0]]\n",
    "        if \"time\" in drmse.dims:\n",
    "            drmse_tmean = drmse.mean(dim=\"time\")\n",
    "        else:\n",
    "            drmse_tmean = drmse\n",
    "        dzmean_rmse[exp] = drmse_tmean / zmean_rmse[expids[0]]\n",
    "        if ntime < 10:\n",
    "            d95[exp] = None\n",
    "        else:\n",
    "            if pfull is not None and levtype != 'surface' and levtype != 'unknown':\n",
    "                ci_coords={\"level\": drmse.level.values,\n",
    "                           \"latitude\": drmse.latitude.values}\n",
    "                ci_dims=[\"level\", \"latitude\"]\n",
    "            else:\n",
    "                ci_coords={\"latitude\": drmse.latitude.values}\n",
    "                ci_dims=[\"latitude\"]\n",
    "            hci = xarray_t_test_interval(drmse,ci_coords,ci_dims,alpha=confidence_level)\n",
    "            d95[exp] = hci / zmean_rmse[expids[0]]\n",
    "    if savedata:\n",
    "        amean.to_netcdf(f'{savedir}/analysis_mean_{vrfy}_f{fhr}.nc')\n",
    "        for e, exp in enumerate(expids):\n",
    "            fmean[exp].to_netcdf(f'{savedir}/fcst_mean_{exp}_f{fhr}.nc')\n",
    "            ermse[exp].to_netcdf(f'{savedir}/rmse_{exp}_f{fhr}.nc')\n",
    "            ebias[exp].to_netcdf(f'{savedir}/bias_{exp}_f{fhr}.nc')\n",
    "            zmean_rmse[exp].to_netcdf(f'{savedir}/zmean_rmse_{exp}_f{fhr}.nc')\n",
    "            if e > 0:\n",
    "                dzmean_rmse[exp].to_netcdf(f'{savedir}/dzmean_rmse_{exp}_f{fhr}.nc')\n",
    "                if ntime >= 10:\n",
    "                    d95[exp].to_netcdf(f'{savedir}/d95_{exp}_f{fhr}.nc')\n",
    "                else:\n",
    "                    d95[exp]=None\n",
    "\n",
    "    return amean, fmean, ermse, ebias, zmean_rmse, dzmean_rmse, d95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e97c4-7955-4ed0-b40d-74101f56b7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a76026-75df-41ab-84e8-fe2ee305408d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57825163-e519-4421-b926-fe379553595e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# main function starts below\n",
    "\n",
    "global analhome, fcsthome, workhome, workdir, savedir, expdic\n",
    "global sdate, edate, delta, vrfy, expids, varids, era5fndic, era5vardic, fhrs\n",
    "global confidence_level, levtype, analdir, aprefix, steptype, avghour\n",
    "\n",
    "era5fndic={'u': 'ua', 'v': 'va', 't': 't', 'q': 'qv', 'clwmr': 'qw',\n",
    "            'ps': 'sp', 'lcc': 'lc'}\n",
    "era5vardic={'clwmr': 'clwc', 'icmr': 'ciwc', 'rwmr': 'crwc', 'snmr': 'cswc'}\n",
    "\n",
    "\"\"\" setup starts here \"\"\"\n",
    "\n",
    "\"\"\" 1. basic setup \"\"\"\n",
    "utildir  = '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/'\n",
    "fcsthome = '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/archive/'\n",
    "analhome = '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/reanalysis_data/ERA5/1x1/'\n",
    "workhome  = '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work/'\n",
    "\n",
    "fighome=utildir+'/figures'\n",
    "savedir=utildir+'/data/'\n",
    "\n",
    "if not os.path.exists(fighome):\n",
    "    os.makedirs(fighome)\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "if not os.path.exists(workhome):\n",
    "    os.makedirs(workhome)\n",
    "    \n",
    "\"\"\" check/modify the following setup variables \"\"\"\n",
    "\"\"\" The first experiment provide analysis for the forecasts of \n",
    "    other experiments to compare with \"\"\"\n",
    "\n",
    "expdic={'IFS': 'ecm', 'gfs': 'gfs',\n",
    "        'FC_ctrl':       'FC_ctrl',\n",
    "        'FC_ctrl_noinf': 'FC_ctrl_noinf'\n",
    "        }\n",
    "\n",
    "expstr='FC_ctrl-FC_ctrl_noinf'\n",
    "expids=expstr.split('-')\n",
    "vrfy='ERA5'\n",
    "\n",
    "#era5prefix='sfc'\n",
    "#era5prefix='pbl'\n",
    "era5prefix='lev'\n",
    "\n",
    "fhrs=['06']\n",
    "varids=['t']\n",
    "\n",
    "\n",
    "\"\"\" levtype: isobaricInhPa, heightAboveGround, surface, unknown \"\"\"\n",
    "levtype='isobaricInhPa'\n",
    "#levtype='unknown'\n",
    "\n",
    "\"\"\" steptype: instant, avg, accum ... \"\"\"\n",
    "#steptype='avg'\n",
    "steptype='instant'\n",
    "avghour=6\n",
    "\n",
    "\n",
    "\"\"\" if running the program again, can read data (.nc) that has been processed without \n",
    "reading grib files again \"\"\"\n",
    "readrawdata=True\n",
    "savedata=True\n",
    "read_mask=False\n",
    "\n",
    "\"\"\" stats configuration \"\"\"\n",
    "confidence_level = 0.995\n",
    "\n",
    "\"\"\" time period \"\"\"\n",
    "sdate=datetime.datetime(2022, 6, 15, 6)\n",
    "edate=datetime.datetime(2022, 6, 16, 6)\n",
    "dhour=24\n",
    "delta = datetime.timedelta(hours=dhour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33d7f7fa-d36d-4bdd-a1fd-9a733055f790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expfix=expids[0]\n",
    "for exp in expids[1:]:\n",
    "    expfix += f'-{exp}'\n",
    "\n",
    "daterange = f'{sdate.strftime(\"%Y%m%d%H\")}_{edate.strftime(\"%Y%m%d%H\")}_{dhour}'\n",
    "savedir   = f'{savedir}/{expfix}/{daterange}/'\n",
    "\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "    \n",
    "workdir = f'{workhome}/{expfix}/{daterange}/'\n",
    "if not os.path.exists(workdir):\n",
    "    os.makedirs(workdir)\n",
    "else:\n",
    "    print(f'caution: files already exist in {workdir}')\n",
    "    #filelist = glob(os.path.join(workdir, \"*\"))\n",
    "    #for f in filelist:\n",
    "    #    os.remove(f)\n",
    "\n",
    "analdir = analhome\n",
    "aprefix = era5prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "282dc401-6196-4bb1-90ab-8a0da3409b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create terrian mask\n",
      "analdir = /scratch2/GFDL/gfdlscr/Chih-Chi.Hu/reanalysis_data/ERA5/1x1/\n",
      "masknc = /scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5//data//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24//mask.nc\n",
      "grib_to_netcdf: Version 2.28.0\n",
      "grib_to_netcdf: Processing input file '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcst.grib'.\n",
      "grib_to_netcdf: Found 36 GRIB fields in 1 file.\n",
      "grib_to_netcdf: Ignoring key(s): method, type, stream, refdate, hdate\n",
      "grib_to_netcdf: Creating netCDF file '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcst.nc'\n",
      "grib_to_netcdf: NetCDF library version: 4.8.1 of Oct 31 2022 22:17:45 $\n",
      "grib_to_netcdf: Creating large (64 bit) file format.\n",
      "grib_to_netcdf: Defining variable 't'.\n",
      "grib_to_netcdf: Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring index file '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcstsp.grib.923a8.idx' older than GRIB file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100286.516 100286.516 100286.516 ... 100286.516 100286.516 100286.516]\n",
      " [100638.516 100636.516 100634.516 ... 100647.516 100644.516 100641.516]\n",
      " [101006.516 100999.516 100991.516 ... 101012.516 101006.516 101006.516]\n",
      " ...\n",
      " [ 71428.516  71363.516  71298.516 ...  71550.516  71511.516  71470.516]\n",
      " [ 70808.516  70787.516  70767.516 ...  70866.516  70847.516  70828.516]\n",
      " [ 70013.516  70013.516  70013.516 ...  70013.516  70013.516  70013.516]]\n",
      "pfulla  [1000.  975.  950.  925.  900.  850.  800.  750.  700.  650.  600.  550.\n",
      "  500.  450.  400.  350.  300.  250.  200.  150.  100.   50.   20.   10.]\n",
      "pfullf  [   0    1    2    3    5    7   10   15   20   30   40   50   70  100\n",
      "  150  200  250  300  350  400  450  500  550  600  650  700  750  800\n",
      "  825  850  875  900  925  950  975 1000]\n",
      "pfull  [  10.   20.   50.  100.  150.  200.  250.  300.  350.  400.  450.  500.\n",
      "  550.  600.  650.  700.  750.  800.  850.  900.  925.  950.  975. 1000.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 1. create mask DataArray \"\"\"\n",
    "if levtype == 'isobaricInhPa':\n",
    "    print ('create terrian mask')\n",
    "    mask = getmask(readmask=read_mask)\n",
    "    pfull = mask.level.values\n",
    "else:\n",
    "    mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f5e03-99a3-4653-9732-41d66ad6f598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e3514f4-a7e5-41d2-8607-fbbeb444f9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast hour 06\n",
      "read raw data and compute stats\n",
      "fcstfn:  /scratch2/GFDL/gfdlscr/Chih-Chi.Hu/archive//FC_ctrl/pgbf06.gdas.2022061500.grib2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/archive//FC_ctrl/pgbf06.gdas.2022061500.grib2: No such file or directory\n",
      "ECCODES ERROR   :  Cannot stat /scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcst.grib (No such file or directory)\n",
      "ECCODES ERROR   :  Input does not contain any field. Exiting!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grib_to_netcdf: Version 2.28.0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work/FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcst.2022061500.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/file_manager.py:209\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work/FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcst.2022061500.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'd3fd2a89-ea93-48da-a4f4-4be06aeefb80']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m readrawdata:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread raw data and compute stats\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     amean, fmean, ermse, ebias, zmean_rmse, dzmean_rmse, d95 \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfhr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43msavedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msavedata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread preprocessed stats\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m, in \u001b[0;36mcompute_stats\u001b[0;34m(fhr, mask, savedata)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     pfull \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m fcst \u001b[38;5;241m=\u001b[39m \u001b[43mread_fcst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfhr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpfull\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m ftime \u001b[38;5;241m=\u001b[39m fcst[expids[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     18\u001b[0m latf \u001b[38;5;241m=\u001b[39m fcst[expids[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mlatitude\u001b[38;5;241m.\u001b[39mvalues\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mread_fcst\u001b[0;34m(cdate, fhr, pfull)\u001b[0m\n\u001b[1;32m     17\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(fcstnc)\n\u001b[1;32m     18\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrib_to_netcdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-D\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNC_FLOAT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m\"\u001b[39m, fcstnc, plgrib])\n\u001b[0;32m---> 20\u001b[0m     fcst[eid] \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfcstnc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msel(level\u001b[38;5;241m=\u001b[39mpfull)\u001b[38;5;241m.\u001b[39misel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[varids]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" single level data \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/api.py:278\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(filename_or_obj, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache has no effect in this context\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mload()\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/api.py:539\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    528\u001b[0m     decode_cf,\n\u001b[1;32m    529\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    536\u001b[0m )\n\u001b[1;32m    538\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 539\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    546\u001b[0m     backend_ds,\n\u001b[1;32m    547\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    556\u001b[0m )\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:572\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    553\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m ):\n\u001b[1;32m    571\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 572\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:376\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    370\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    371\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    373\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    374\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    375\u001b[0m )\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:323\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:385\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/netCDF4_.py:379\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    380\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/file_manager.py:197\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/miniconda3/envs/env1/lib/python3.8/site-packages/xarray/backends/file_manager.py:215\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    213\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    214\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 215\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work/FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcst.2022061500.nc'"
     ]
    }
   ],
   "source": [
    "\"\"\"2. read data and compute error stats \"\"\"\n",
    "famean={}; ffmean={}; fbias={}; frmse={}; fzmean_rmse={}; fdzmean_rmse={}; fd95={}\n",
    "for f, fhr in enumerate(fhrs):\n",
    "    print (f'forecast hour {fhr}')\n",
    "    if readrawdata:\n",
    "        print ('read raw data and compute stats')\n",
    "        amean, fmean, ermse, ebias, zmean_rmse, dzmean_rmse, d95 = compute_stats(fhr,mask,savedata=savedata)\n",
    "    else:\n",
    "        print ('read preprocessed stats')\n",
    "        amean, fmean, ermse, ebias, zmean_rmse, dzmean_rmse, d95 = read_stats(fhr)\n",
    "\n",
    "    famean[fhr]=amean; ffmean[fhr]=fmean; frmse[fhr]=ermse; fbias[fhr]=ebias\n",
    "    fzmean_rmse[fhr]=zmean_rmse; fdzmean_rmse[fhr]=dzmean_rmse; fd95[fhr]=d95\n",
    "\n",
    "    if f == 0:\n",
    "        \"\"\"  get area of lat/lon grid box \"\"\"\n",
    "        lat=amean.latitude.values\n",
    "        lon=amean.longitude.values\n",
    "        lath, latl, weight = glib.area_weight(lat,lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53689867-e99b-4394-bd74-5890fa2ed69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056419ed-5f68-4cf7-87b7-32e0ce6ed520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad1682-2088-4aab-a847-49fe7ec6932c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70212e84-0d62-4f16-a298-3a55ef2aa68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45007bcc-808d-4971-ac62-93b43ebd8ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5cbcbb3-77aa-484d-81a3-0889ed0974e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analdir = /scratch2/GFDL/gfdlscr/Chih-Chi.Hu/reanalysis_data/ERA5/1x1/\n",
      "masknc = /scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5//data//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24//mask.nc\n",
      "grib_to_netcdf: Version 2.28.0\n",
      "grib_to_netcdf: Processing input file '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcst.grib'.\n",
      "grib_to_netcdf: Found 36 GRIB fields in 1 file.\n",
      "grib_to_netcdf: Ignoring key(s): method, type, stream, refdate, hdate\n",
      "grib_to_netcdf: Creating netCDF file '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcst.nc'\n",
      "grib_to_netcdf: NetCDF library version: 4.8.1 of Oct 31 2022 22:17:45 $\n",
      "grib_to_netcdf: Creating large (64 bit) file format.\n",
      "grib_to_netcdf: Defining variable 't'.\n",
      "grib_to_netcdf: Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring index file '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcstsp.grib.923a8.idx' older than GRIB file\n",
      "Ignoring index file '/scratch2/GFDL/gfdlscr/Chih-Chi.Hu/forecast_verification_ERA5/work//FC_ctrl-FC_ctrl_noinf/2022061506_2022061606_24/fcstsp.grib.923a8.idx' older than GRIB file\n"
     ]
    }
   ],
   "source": [
    "print (f'analdir = {analdir}')\n",
    "masknc = f'{savedir}/mask.nc'\n",
    "print (f'masknc = {masknc}')\n",
    "    \n",
    "\"\"\" get surface pressure from experiment forecast \"\"\"\n",
    "fcstdate = sdate-datetime.timedelta(hours=6)\n",
    "fcstcyc  = fcstdate.strftime(\"%Y%m%d%H\")\n",
    "fhr=fhrs[0]\n",
    "ne=0\n",
    "for e, eid in enumerate(expids):\n",
    "    fcstfn = os.path.join(f'{fcsthome}/{expdic[eid]}',f'pgbf{fhr}.gfs.{fcstcyc}.grib2')\n",
    "    plgrib = os.path.join(f'{workdir}', 'fcst.grib')\n",
    "    fcstnc = os.path.join(f'{workdir}', 'fcst.nc')\n",
    "    spgrib = os.path.join(f'{workdir}', 'fcstsp.grib')\n",
    "    \"\"\" assuming all forecast files have the same dimension \"\"\"\n",
    "    if e == 0:\n",
    "        if os.path.exists(plgrib):\n",
    "            os.remove(plgrib)\n",
    "        subprocess.run([\"grib_copy\", \"-w\", \"levtype=pl,shortName=t\", fcstfn, plgrib])\n",
    "        subprocess.run([\"grib_to_netcdf\", \"-D\" \"NC_FLOAT\", \"-o\", fcstnc, plgrib])\n",
    "        fcst   = xr.load_dataset(fcstnc)\n",
    "        ftime  = fcst.time.values[0]\n",
    "        pfullf = fcst.level.values\n",
    "        latf   = fcst.latitude.values\n",
    "        lonf   = fcst.longitude.values\n",
    "    if os.path.exists(spgrib):\n",
    "        os.remove(spgrib)\n",
    "    subprocess.run([\"grib_copy\", \"-w\", \"shortName=sp\", fcstfn, spgrib]) # sp = sea pressure\n",
    "    fcstsp = xr.load_dataset(spgrib, engine=\"cfgrib\")\n",
    "    if e == 0:\n",
    "        psfc = fcstsp.sp.values\n",
    "    else:\n",
    "        psfc = psfc + fcstsp.sp.values\n",
    "    ne += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87b17801-ad22-4602-be96-3fc962def570",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100286.516 100286.516 100286.516 ... 100286.516 100286.516 100286.516]\n",
      " [100638.516 100636.516 100634.516 ... 100647.516 100644.516 100641.516]\n",
      " [101006.516 100999.516 100991.516 ... 101012.516 101006.516 101006.516]\n",
      " ...\n",
      " [ 71428.516  71363.516  71298.516 ...  71550.516  71511.516  71470.516]\n",
      " [ 70808.516  70787.516  70767.516 ...  70866.516  70847.516  70828.516]\n",
      " [ 70013.516  70013.516  70013.516 ...  70013.516  70013.516  70013.516]]\n",
      "pfulla  [1000.  975.  950.  925.  900.  850.  800.  750.  700.  650.  600.  550.\n",
      "  500.  450.  400.  350.  300.  250.  200.  150.  100.   50.   20.   10.]\n",
      "pfullf  [   0    1    2    3    5    7   10   15   20   30   40   50   70  100\n",
      "  150  200  250  300  350  400  450  500  550  600  650  700  750  800\n",
      "  825  850  875  900  925  950  975 1000]\n",
      "pfull  [  10.   20.   50.  100.  150.  200.  250.  300.  350.  400.  450.  500.\n",
      "  550.  600.  650.  700.  750.  800.  850.  900.  925.  950.  975. 1000.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" get surface pressure from analysis \"\"\"\n",
    "analcyc = sdate.strftime(\"%Y%m%d%H\")\n",
    "ayyyy   = analcyc[:4]\n",
    "amm     = analcyc[4:6]\n",
    "\n",
    "analnc = os.path.join(analdir, f'{aprefix}.{era5fndic[varids[0]]}.{ayyyy}.{amm}.nc')\n",
    "spnc   = os.path.join(analdir, f'sfc.ps.{ayyyy}.{amm}.nc')\n",
    "\n",
    "\"\"\" get analysis pressure levels \"\"\"\n",
    "if not os.path.exists(analnc):\n",
    "    raise SystemExit(f'{analnc} not exist')\n",
    "anal   = xr.load_dataset(analnc).sel(valid_time=ftime)\n",
    "pfulla = anal.pressure_level.values\n",
    "\n",
    "\"\"\" analysis surface pressure \"\"\"\n",
    "if not os.path.exists(spnc):\n",
    "    raise SystemExit(f'{spnc} not exist')\n",
    "analsp = xr.load_dataset(spnc).sel(valid_time=ftime)\n",
    "\n",
    "\"\"\" regrid ERA5 dataset to forecast dataset resolution \"\"\"\n",
    "lata = analsp.latitude.values\n",
    "lona = analsp.longitude.values\n",
    "\n",
    "if not np.array_equiv(lata,latf) or not np.array_equiv(lona,lonf):\n",
    "    ds_out = xr.Dataset(\n",
    "        {\n",
    "           \"lat\": ([\"lat\"], latf),\n",
    "           \"lon\": ([\"lon\"], lonf),\n",
    "        }\n",
    "    )\n",
    "    regridder = xe.Regridder(analsp, ds_out, \"bilinear\")\n",
    "    analsp = regridder(analsp)\n",
    "\n",
    "print (analsp.sp.values)\n",
    "psfc = psfc + analsp.sp.values\n",
    "ne += 1\n",
    "ne_inv=0.01/ne\n",
    "psfc = psfc * ne_inv\n",
    "\n",
    "psfcarray=xr.DataArray(\n",
    "data=psfc,\n",
    "coords={\n",
    "    \"latitude\": latf,\n",
    "    \"longitude\": lonf,\n",
    "},\n",
    "dims=[\"latitude\", \"longitude\"],\n",
    "name='psfc'\n",
    ")\n",
    "\n",
    "psfcarray.to_netcdf(f'{savedir}/psfc.nc')\n",
    "\n",
    "\"\"\" create mask DataArray \"\"\"\n",
    "maskdata = np.ones(fcst.t.values.shape, dtype=bool)\n",
    "pfull    = np.intersect1d(pfulla,pfullf)\n",
    "print ('pfulla ', pfulla)\n",
    "print ('pfullf ', pfullf)\n",
    "print ('pfull ', pfull)\n",
    "maskdata = np.ones((len(pfull), psfc.shape[0], psfc.shape[1]))\n",
    "for l, pres in enumerate(pfull.tolist()):\n",
    "    cutoff=800\n",
    "    if pres < cutoff:\n",
    "        cutoff = pres\n",
    "    maskdata[l,:,:] = (psfc > cutoff)\n",
    "\n",
    "mask=xr.DataArray(\n",
    "data=maskdata,\n",
    "coords={\n",
    "    \"level\": pfull,\n",
    "    \"latitude\": latf,\n",
    "    \"longitude\": lonf,\n",
    "},\n",
    "dims=[\"level\", \"latitude\", \"longitude\"],\n",
    "name='mask'\n",
    ")\n",
    "\n",
    "mask.to_netcdf(masknc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
